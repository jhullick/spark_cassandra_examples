{"paragraphs":[{"text":"//access Cassandra keyspark.table\r\nval keySpace = \"cloudcomputing\"\r\nval table = \"data\"\r\n\r\nval fullTable = sqlContext.read.format(\"org.apache.spark.sql.cassandra\").options(Map(\"keyspace\" -> keySpace, \"table\" -> table)).load()\r\ndf.createOrReplaceTempView(table)","user":"anonymous","dateUpdated":"2018-08-05T10:00:10+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533461109454_-415201366","id":"20180805-092509_334814974","dateCreated":"2018-08-05T09:25:09+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:15272","dateFinished":"2018-08-05T10:00:10+0000","dateStarted":"2018-08-05T10:00:10+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"keySpace: String = cloudcomputing\ntable: String = data\nfullTable: org.apache.spark.sql.DataFrame = [campus: string, date: timestamp ... 2 more fields]\n"}]}},{"text":"// retrieve records of one partition. \r\nval onePartition = fullTable.filter($\"campus\" === \"St Lucia\").select($\"date\", $\"sensor_id\", $\"temperature\") \r\n\r\nz.show(onePartition)","user":"anonymous","dateUpdated":"2018-08-05T10:00:10+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"1":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"date":"string","sensor_id":"string","temperature":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533461159891_-1823488455","id":"20180805-092559_1136160711","dateCreated":"2018-08-05T09:25:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15273","dateFinished":"2018-08-05T10:00:11+0000","dateStarted":"2018-08-05T10:00:10+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"onePartition: org.apache.spark.sql.DataFrame = [date: timestamp, sensor_id: int ... 1 more field]\n"},{"type":"TABLE","data":"date\tsensor_id\ttemperature\n2018-06-01 00:00:00.0\t1\t26.1\n2018-06-01 00:00:00.0\t2\t26.5\n2018-06-01 00:00:00.0\t3\t25.0\n2018-06-02 00:00:00.0\t1\t28.5\n2018-06-02 00:00:00.0\t2\t29.0\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.23.97.168:4040/jobs/job?id=137"],"interpreterSettingId":"spark"}}},{"text":"// use map reduce to calculate average temperature of each date\r\n// step 1 map: one row -> one record\r\nval records = onePartition.as[(String,Int,Float)].map{\r\n    case (date, sensor_id, temperature) => (date, (1, temperature))\r\n}\r\n\r\nval columnNames = Array(\"date\", \"count_temperate\")\r\n\r\nz.show(records.toDF(columnNames:_*))","user":"anonymous","dateUpdated":"2018-08-05T10:00:11+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"1":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"date":"string","count_temperate":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533461199266_-882221233","id":"20180805-092639_571996403","dateCreated":"2018-08-05T09:26:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15274","dateFinished":"2018-08-05T10:00:12+0000","dateStarted":"2018-08-05T10:00:11+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"records: org.apache.spark.sql.Dataset[(String, (Int, Float))] = [_1: string, _2: struct<_1: int, _2: float>]\ncolumnNames: Array[String] = Array(date, count_temperate)\n"},{"type":"TABLE","data":"date\tcount_temperate\n2018-06-01 00:00:00\t[1,26.1]\n2018-06-01 00:00:00\t[1,26.5]\n2018-06-01 00:00:00\t[1,25.0]\n2018-06-02 00:00:00\t[1,28.5]\n2018-06-02 00:00:00\t[1,29.0]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.23.97.168:4040/jobs/job?id=138"],"interpreterSettingId":"spark"}}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"1":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"date":"string","count_sum":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533461610588_-796594635","id":"20180805-093330_1863280248","dateCreated":"2018-08-05T09:33:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:17473","text":"// use map reduce to calculate average temperature of each date\r\n// step 2 reduceByKey: two records within one group -> one (count, sum)\r\nval sum = records.rdd.reduceByKey{\r\n    (a,b) => (a._1+b._1, a._2+b._2)\r\n}\r\n\r\nval columnNames = Array(\"date\", \"count_sum\")\r\n\r\nz.show(sum.toDF(columnNames:_*))","dateUpdated":"2018-08-05T10:00:12+0000","dateFinished":"2018-08-05T10:00:12+0000","dateStarted":"2018-08-05T10:00:12+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"sum: org.apache.spark.rdd.RDD[(String, (Int, Float))] = ShuffledRDD[692] at reduceByKey at <console>:38\ncolumnNames: Array[String] = Array(date, count_sum)\n"},{"type":"TABLE","data":"date\tcount_sum\n2018-06-02 00:00:00\t[2,57.5]\n2018-06-01 00:00:00\t[3,77.6]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.23.97.168:4040/jobs/job?id=139"],"interpreterSettingId":"spark"}}},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"1":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"date":"string","avg_temp":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533461936732_-1238792563","id":"20180805-093856_1650193494","dateCreated":"2018-08-05T09:38:56+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:19855","text":"// use map reduce to calculate average temperature of each date\r\n// step 3 map: one (count, sum) -> one average\r\nval average = sum.map{\r\n    case (date, (count, sum)) => (date, sum/count)\r\n}\r\n\r\nval columnNames = Array(\"date\", \"avg_temp\")\r\n\r\nz.show(average.toDF(columnNames:_*))","dateUpdated":"2018-08-05T10:00:12+0000","dateFinished":"2018-08-05T10:00:13+0000","dateStarted":"2018-08-05T10:00:13+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"average: org.apache.spark.rdd.RDD[(String, Float)] = MapPartitionsRDD[696] at map at <console>:40\ncolumnNames: Array[String] = Array(date, avg_temp)\n"},{"type":"TABLE","data":"date\tavg_temp\n2018-06-02 00:00:00\t28.75\n2018-06-01 00:00:00\t25.866667\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.23.97.168:4040/jobs/job?id=140"],"interpreterSettingId":"spark"}}},{"text":"// use map reduce to calculate average temperature of each date\r\n// combine steps 1, 2, 3\r\nval average = onePartition.as[(String,Int,Float)].map{\r\n    case (date, sensor_id, temperature) => (date, (1, temperature))\r\n}.rdd.reduceByKey{\r\n    (a,b) => (a._1+b._1, a._2+b._2)\r\n}.map{\r\n    case (date, (count, sum)) => (date, sum/count)\r\n}\r\n\r\nval columnNames = Array(\"date\", \"ave_temp\")\r\n\r\nz.show(average.toDF(columnNames:_*))","user":"anonymous","dateUpdated":"2018-08-05T10:00:14+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"1":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"date":"string","ave_temp":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533461262522_685596357","id":"20180805-092742_1071002342","dateCreated":"2018-08-05T09:27:42+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15275","dateFinished":"2018-08-05T10:00:15+0000","dateStarted":"2018-08-05T10:00:14+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"average: org.apache.spark.rdd.RDD[(String, Float)] = MapPartitionsRDD[708] at map at <console>:44\ncolumnNames: Array[String] = Array(date, ave_temp)\n"},{"type":"TABLE","data":"date\tave_temp\n2018-06-02 00:00:00\t28.75\n2018-06-01 00:00:00\t25.866667\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.23.97.168:4040/jobs/job?id=141"],"interpreterSettingId":"spark"}}}],"name":"use map reduce to calculate average of each group","id":"2DMSD9JN3","noteParams":{},"noteForms":{},"angularObjects":{"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}