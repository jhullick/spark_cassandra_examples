{"paragraphs":[{"text":"val keySpace = \"cloudcomputing\"\r\nval table = \"data\"\r\n\r\nval dataframe = sqlContext.read.format(\"org.apache.spark.sql.cassandra\").options(Map(\"keyspace\" -> keySpace, \"table\" -> table)).load()","user":"anonymous","dateUpdated":"2018-08-03T04:18:00+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"keySpace: String = cloudcomputing\ntable: String = data\ndataframe: org.apache.spark.sql.DataFrame = [campus: string, date: timestamp ... 2 more fields]\n"}]},"apps":[],"jobName":"paragraph_1532935447431_-1012564149","id":"20180730-072407_799047552","dateCreated":"2018-07-30T07:24:07+0000","dateStarted":"2018-08-03T04:18:00+0000","dateFinished":"2018-08-03T04:18:00+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1440"},{"text":"// select data, sensor_id, temperature from data where campus = 'St Lucia' \r\nval df1 = dataframe.filter($\"campus\" === \"St Lucia\").select($\"date\", $\"sensor_id\", $\"temperature\") //one time one partition, more than one partition cause full table scan\r\ndf1.show()","user":"anonymous","dateUpdated":"2018-08-03T04:18:00+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"df1: org.apache.spark.sql.DataFrame = [date: timestamp, sensor_id: int ... 1 more field]\n+-------------------+---------+-----------+\n|               date|sensor_id|temperature|\n+-------------------+---------+-----------+\n|2018-06-01 00:00:00|        1|       26.1|\n|2018-06-01 00:00:00|        2|       26.5|\n|2018-06-01 00:00:00|        3|       25.0|\n|2018-06-02 00:00:00|        1|       28.5|\n|2018-06-02 00:00:00|        2|       29.0|\n+-------------------+---------+-----------+\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.23.97.168:4040/jobs/job?id=19"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1533023986108_1403435731","id":"20180731-075946_2118817073","dateCreated":"2018-07-31T07:59:46+0000","dateStarted":"2018-08-03T04:18:00+0000","dateFinished":"2018-08-03T04:18:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1441"},{"text":"// select avg(temperature) as avg_temp\r\n// from data\r\n// where campus = 'St Lucia' \r\n// group by campus\r\n\r\nval rdd2 = df1.as[(String,Int,Float)].map{\r\n    case (date, sensor_id, temperature) => (1, temperature)\r\n}.reduce{\r\n    (a,b) => (a._1+b._1, a._2+b._2)\r\n}\r\n\r\nprintln(\"avg_temp: \" + rdd2._2/rdd2._1)","user":"anonymous","dateUpdated":"2018-08-03T04:18:01+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rdd2: (Int, Float) = (5,135.1)\navg_temp: 27.02\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.23.97.168:4040/jobs/job?id=20"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1532935592965_1585704852","id":"20180730-072632_942137842","dateCreated":"2018-07-30T07:26:32+0000","dateStarted":"2018-08-03T04:18:01+0000","dateFinished":"2018-08-03T04:18:02+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1442"},{"text":"// select date, avg(temperature) as avg_temp_day\r\n// from data\r\n// where campus = 'St Lucia'\r\n// group by date\r\n\r\nval rdd3 = df1.as[(String,Int,Float)].map{\r\n    case (date, sensor_id, temperature) => (date, (1, temperature))\r\n}.rdd.reduceByKey{\r\n    (a,b) => (a._1+b._1, a._2+b._2)\r\n}.map{\r\n    case (date, (count, sum)) => (date, sum/count)\r\n}\r\n\r\nrdd3.toDF(Array(\"date\", \"ave_temp_date\"):_*).show","user":"anonymous","dateUpdated":"2018-08-03T04:18:02+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rdd3: org.apache.spark.rdd.RDD[(String, Float)] = MapPartitionsRDD[133] at map at <console>:42\n+-------------------+-------------+\n|               date|ave_temp_date|\n+-------------------+-------------+\n|2018-06-02 00:00:00|        28.75|\n|2018-06-01 00:00:00|    25.866667|\n+-------------------+-------------+\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.23.97.168:4040/jobs/job?id=21"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1533024011190_-787109138","id":"20180731-080011_145400584","dateCreated":"2018-07-31T08:00:11+0000","dateStarted":"2018-08-03T04:18:02+0000","dateFinished":"2018-08-03T04:18:04+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1443"},{"user":"anonymous","dateUpdated":"2018-08-03T04:18:04+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533024178883_1240426877","id":"20180731-080258_177954100","dateCreated":"2018-07-31T08:02:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1444"}],"name":"mapreduce","id":"2DJSW6UQC","noteParams":{},"noteForms":{},"angularObjects":{"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}